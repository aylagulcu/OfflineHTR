{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import islice\n",
    "import shutil\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE_TRAIN = 30000\n",
    "DATASET_SIZE_VALIDATION = 10000\n",
    "DATASET_SIZE_TEST = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"..\\Authors\"\n",
    "\n",
    "train = open(\"train_\" + str(DATASET_SIZE_TRAIN)+ \".txt\",\"w\")\n",
    "valid = open(\"valid_\" + str(DATASET_SIZE_VALIDATION)+ \".txt\",\"w\")\n",
    "test  = open(\"test_\" + str(DATASET_SIZE_TEST)+ \".txt\",\"w\")\n",
    "\n",
    "author_paths = glob.glob(os.path.join(dataset_path,'*'))\n",
    "\n",
    "author_ids = []\n",
    "for i in range(len(author_paths)):\n",
    "    author_ids.append(author_paths[i][-3:])\n",
    "\n",
    "print(author_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1,idx2 = 0,0\n",
    "pos_id = 0\n",
    "neg_ids = (0,0)\n",
    "poslabel = 1\n",
    "neglabel = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_files=dict()\n",
    "existing_pairs = dict()\n",
    "existing_pairs_valid = dict()\n",
    "existing_pairs_train = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DictHavePair(item1,item2,dictionary):\n",
    "    if dictionary.get((item1,item2)) is None :\n",
    "        dictionary[(item1,item2)] = \"\"\n",
    "        return False\n",
    "    else :\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(DATASET_SIZE_TEST/2)):\n",
    "    print(i)\n",
    "    # Randomly get author IDs for positive and negative pairs\n",
    "    pos_id = author_paths[random.randint(0,99)]\n",
    "    neg_ids = (author_paths[random.randint(0,99)],author_paths[random.randint(0,99)])\n",
    "\n",
    "    # Ensure different author ids for negative pair\n",
    "    while neg_ids[0] == neg_ids[1]:\n",
    "        neg_ids = (author_paths[random.randint(0,99)],author_paths[random.randint(0,99)])\n",
    "\n",
    "    # Randomly get writing samples from each author id\n",
    "    pos_filepaths = glob.glob(os.path.join(pos_id,\"*.png\"))\n",
    "    idx1,idx2 = random.randint(0,len(pos_filepaths)-1),random.randint(0,len(pos_filepaths)-1)\n",
    "\n",
    "    # Ensure positive writing samples are not the same sample\n",
    "    while idx1 == idx2 or DictHavePair(pos_filepaths[idx1],pos_filepaths[idx2],existing_pairs):\n",
    "        idx1,idx2 = random.randint(0,len(pos_filepaths)-1),random.randint(0,len(pos_filepaths)-1)\n",
    "\n",
    "    # Write positive example\n",
    "    \n",
    "    test.write(pos_filepaths[idx1]+' '+pos_filepaths[idx2]+' '+str(poslabel)+'\\n')\n",
    "    \n",
    "    #Add examples to used files\n",
    "    used_files[pos_filepaths[idx1]] = used_files.get(pos_filepaths[idx1],0) + 1\n",
    "    used_files[pos_filepaths[idx2]] = used_files.get(pos_filepaths[idx2],0) + 1\n",
    "    \n",
    "    \n",
    "    neg_filepaths = (glob.glob(os.path.join(neg_ids[0],\"*.png\")),glob.glob(os.path.join(neg_ids[1],\"*.png\")))\n",
    "    idx1,idx2 = random.randint(0,len(neg_filepaths[0])-1),random.randint(0,len(neg_filepaths[1])-1)\n",
    "    while DictHavePair(neg_filepaths[0][idx1],neg_filepaths[1][idx2],existing_pairs) :\n",
    "        idx1,idx2 = random.randint(0,len(neg_filepaths[0])-1),random.randint(0,len(neg_filepaths[1])-1)\n",
    "    # Write negative example\n",
    "    test.write(neg_filepaths[0][idx1]+' '+neg_filepaths[1][idx2]+' '+str(neglabel)+'\\n')\n",
    "    \n",
    "    #Add Examples to used files\n",
    "    used_files[neg_filepaths[0][idx1]] = used_files.get(neg_filepaths[0][idx1],0) + 1\n",
    "    used_files[neg_filepaths[1][idx2]] = used_files.get(neg_filepaths[1][idx2],0) + 1\n",
    "\n",
    "test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(used_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(existing_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DictHavePairWithUsedCheck(item1,item2,dictionary,useddictionary):\n",
    "    if dictionary.get((item1,item2)) is None and  useddictionary.get(item1) is None and useddictionary.get(item2):\n",
    "        dictionary[(item1,item2)] = \"\"\n",
    "        return False\n",
    "    else :\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(DATASET_SIZE_VALIDATION/2)):\n",
    "    print(i)\n",
    "    # Randomly get author IDs for positive and negative pairs\n",
    "    pos_id = author_paths[random.randint(0,99)]\n",
    "    neg_ids = (author_paths[random.randint(0,99)],author_paths[random.randint(0,99)])\n",
    "\n",
    "    # Ensure different author ids for negative pair\n",
    "    while neg_ids[0] == neg_ids[1]:\n",
    "        neg_ids = (author_paths[random.randint(0,99)],author_paths[random.randint(0,99)])\n",
    "\n",
    "    # Randomly get writing samples from each author id\n",
    "    pos_filepaths = glob.glob(os.path.join(pos_id,\"*.png\"))\n",
    "    idx1,idx2 = random.randint(0,len(pos_filepaths)-1),random.randint(0,len(pos_filepaths)-1)\n",
    "\n",
    "    # Ensure positive writing samples are not the same sample\n",
    "    while idx1 == idx2 or DictHavePairWithUsedCheck(pos_filepaths[idx1],pos_filepaths[idx2],existing_pairs_valid,used_files):\n",
    "        idx1,idx2 = random.randint(0,len(pos_filepaths)-1),random.randint(0,len(pos_filepaths)-1)\n",
    "\n",
    "    # Write positive example\n",
    "    \n",
    "    valid.write(pos_filepaths[idx1]+' '+pos_filepaths[idx2]+' '+str(poslabel)+'\\n')\n",
    "    \n",
    "    \n",
    "    neg_filepaths = (glob.glob(os.path.join(neg_ids[0],\"*.png\")),glob.glob(os.path.join(neg_ids[1],\"*.png\")))\n",
    "    idx1,idx2 = random.randint(0,len(neg_filepaths[0])-1),random.randint(0,len(neg_filepaths[1])-1)\n",
    "    while DictHavePairWithUsedCheck(neg_filepaths[0][idx1],neg_filepaths[1][idx2],existing_pairs_valid,used_files) :\n",
    "        idx1,idx2 = random.randint(0,len(neg_filepaths[0])-1),random.randint(0,len(neg_filepaths[1])-1)\n",
    "    # Write negative example\n",
    "    valid.write(neg_filepaths[0][idx1]+' '+neg_filepaths[1][idx2]+' '+str(neglabel)+'\\n')\n",
    "    \n",
    "\n",
    "valid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(existing_pairs_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(used_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(DATASET_SIZE_TRAIN/2)):\n",
    "    print(i)\n",
    "    # Randomly get author IDs for positive and negative pairs\n",
    "    pos_id = author_paths[random.randint(0,99)]\n",
    "    neg_ids = (author_paths[random.randint(0,99)],author_paths[random.randint(0,99)])\n",
    "\n",
    "    # Ensure different author ids for negative pair\n",
    "    while neg_ids[0] == neg_ids[1]:\n",
    "        neg_ids = (author_paths[random.randint(0,99)],author_paths[random.randint(0,99)])\n",
    "\n",
    "    # Randomly get writing samples from each author id\n",
    "    pos_filepaths = glob.glob(os.path.join(pos_id,\"*.png\"))\n",
    "    idx1,idx2 = random.randint(0,len(pos_filepaths)-1),random.randint(0,len(pos_filepaths)-1)\n",
    "\n",
    "    # Ensure positive writing samples are not the same sample\n",
    "    while idx1 == idx2 or DictHavePairWithUsedCheck(pos_filepaths[idx1],pos_filepaths[idx2],existing_pairs_train,used_files):\n",
    "        idx1,idx2 = random.randint(0,len(pos_filepaths)-1),random.randint(0,len(pos_filepaths)-1)\n",
    "\n",
    "    # Write positive example\n",
    "    \n",
    "    train.write(pos_filepaths[idx1]+' '+pos_filepaths[idx2]+' '+str(poslabel)+'\\n')\n",
    "    \n",
    "    \n",
    "    neg_filepaths = (glob.glob(os.path.join(neg_ids[0],\"*.png\")),glob.glob(os.path.join(neg_ids[1],\"*.png\")))\n",
    "    idx1,idx2 = random.randint(0,len(neg_filepaths[0])-1),random.randint(0,len(neg_filepaths[1])-1)\n",
    "    while DictHavePairWithUsedCheck(neg_filepaths[0][idx1],neg_filepaths[1][idx2],existing_pairs_train,used_files) :\n",
    "        idx1,idx2 = random.randint(0,len(neg_filepaths[0])-1),random.randint(0,len(neg_filepaths[1])-1)\n",
    "    # Write negative example\n",
    "    train.write(neg_filepaths[0][idx1]+' '+neg_filepaths[1][idx2]+' '+str(neglabel)+'\\n')\n",
    "    \n",
    "\n",
    "train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(existing_pairs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-rogers",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
